{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint conf-call report #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-04 11:49:43.104378\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For this second report I am experimenting a new way to fastly deploy updates about the project: **Jupyter notebook**. In this stage of the project, I'd like to share more code snippets than I would in the final thesis, hence markdown support and live execution of code snippets turned out to be very useful for such purpose. Actually the two main reason why I decided to move from raw LaTeX to here are: (1) Jupyter does it faster, (2) it converts everything to LaTeX (I won't be required to make any effort to include everything from here to my LaTeX thesis document). Whether, for any reason, this method will turn out to be ineffective or time-expensive, then I will drop it out._\n",
    "\n",
    "_You will notice changes in style, format and even contents (like change logs and other stuffs that may appear useless or too much detailed), this necessity arises since I need to keep track of the internship's history and I foresee that within few months the commit log on Github will get a bit messy and too much wide to be relied on, instead these reports are the easiest way to fulfill such task._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change log summary\n",
    "\n",
    "## Training set generator function\n",
    "Now domains of all samples' components are centered at the same value $c$. Such domains are determined as follows.\n",
    "\n",
    "Is defined $K = \\{k_1,...k_m\\}$ where $k_i$ is the domain radius of variable $x_i$.\n",
    "Let $x=(x_1,...,x_m) \\in X$ be a sample of the training set, then the domain of $x_i$ is $D(x_i) = [c-k_i, c+k_i]$.\n",
    "\n",
    "\n",
    "```python\n",
    "def sample_from_function(n_samples, n_features, func, domain_radius=0.5, domain_center=0.5, error_mean=0, error_std_dev=1):\n",
    "    X = []\n",
    "    y = np.zeros(n_samples)\n",
    "    w = np.ones(n_features)\n",
    "    K = np.random.uniform(domain_center - domain_radius, domain_center + domain_radius, n_features)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        x = np.zeros(n_features)\n",
    "        for j in range(n_features):\n",
    "            x[j] = np.random.uniform(-K[j] + domain_radius, K[j] + domain_radius)\n",
    "        X.append(x)\n",
    "        y[i] = func(x, w) + np.random.normal(error_mean, error_std_dev)\n",
    "\n",
    "return np.array(X), y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**. Detailed execution of `sample_from_function` with the following parameters:\n",
    "- `n_samples = 8` : amount of samples in the training set;\n",
    "- `n_features = 4` : number of features, e.g. size of each sample's array;\n",
    "- `func` : classic linear function $f(\\vec{x},\\vec{w})=\\sum_{j=1}^{m} x_j w_j$ where $m$ is the size of $x$ (and $w$), so, for instance, $f((2,3),(4,1))=2*4+3*1=11$;\n",
    "- `domain_radius = 5`;\n",
    "- `domain_center = 0`;\n",
    "- `error_mean = 0` and `error_std_dev = 1`: the error (noise) is normally distributed with $\\mu = 0$ and $\\sigma = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.00713793 -0.33902602  0.13068124  1.6246818 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "n_samples = 8\n",
    "n_features = 4\n",
    "func = lambda _X,_w : _X.dot(_w)\n",
    "domain_center = 0\n",
    "domain_radius = 5\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "X = []\n",
    "y = np.zeros(n_samples)\n",
    "w = np.ones(n_features)\n",
    "K = np.random.uniform(domain_center - domain_radius, domain_center + domain_radius, n_features)\n",
    "\n",
    "print(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the centers of variables $x_1, x_2, x_3$ and $x_4$ respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "[   array([1.14678659, 4.72191439, 4.88513418, 4.385389  ]),\n",
      "    array([6.3692572 , 5.30138619, 5.01406369, 5.63875345]),\n",
      "    array([4.67455441, 5.21725698, 5.02592469, 5.45187453]),\n",
      "    array([8.22688716, 5.23973922, 5.01244772, 5.39299295]),\n",
      "    array([6.31345814, 4.74067851, 5.02559019, 5.67637608]),\n",
      "    array([1.11971923, 4.88378811, 4.88175249, 6.00179764]),\n",
      "    array([2.11584329, 4.96572785, 5.04728619, 5.44922452]),\n",
      "    array([7.86286299, 4.94175031, 5.12274525, 4.64251712])]\n",
      "y = array([15.78801252, 22.09363563, 19.78453008, 24.20968846, 22.6499015 ,\n",
      "       15.91160444, 17.96298163, 24.32308662])\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_samples):\n",
    "    x = np.zeros(n_features)\n",
    "    for j in range(n_features):\n",
    "        x[j] = np.random.uniform(-K[j] + domain_radius, K[j] + domain_radius)\n",
    "    X.append(x)\n",
    "    y[i] = func(x, w) + np.random.normal(error_mean, error_std_dev)\n",
    "print(\"X = \\n\" + pprint.PrettyPrinter(indent=4).pformat(X))\n",
    "print(\"y = \" + pprint.PrettyPrinter(indent=4).pformat(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is printed the training set $\\mathcal{X} = (X,y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metric Real Mean Squared Error (RMSE)\n",
    "The training set is in the form of a pair $(X,y)$ where $y_i$ is the value the target function is supposed to yield for the input $x_i$, actually, whether a noise exists in the training set, then $y_i$ differs from the real value $\\tilde{y}_i$ by a gap that, in our case, is normally distributed (with mean = `error_mean` and standard deviation = `error_std_dev`). Whereas the training set is generated with fully control over all parameters, we know either the perturbed value $y_i$ either the real value $\\tilde{y}_i=\\mathbb{1} x_i=\\sum_{j=1}^{m}x_{ij}$, so we have an additional information to take into account in order to study behaviour of different models.\n",
    "\n",
    "While the mean squared error\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^{n} (y_i - \\hat{y}_i) (\\hat{y}_i)'$$\n",
    "regards $y_i$, the _real mean squared error_ (RMSE) concerns $\\tilde{y}_i$, hence it's defined as\n",
    "$$RMSE = \\frac{1}{N} \\sum_{i=1}^{n} (\\tilde{y}_i - \\hat{y}_i) (\\hat{y}_i)'.$$\n",
    "\n",
    "By comparing these two metrics one can understand whether and how much the prediction model suffers from noise fitting, e.g. when the model adapts itself much more on the noise rather than on the provided target function value.\n",
    "\n",
    "Obviously, noiseless training sets lead the MSE to be equal to the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the error over the whole training set\n",
    "After each iteration each node computes a set of metrics taking into account its local model and knowledge, so each node keeps track of the history of its weight vector, MAE (mean absolute error), RMAE (to be implemented yet), MSE, RMSE.\n",
    "\n",
    "Previously I computed the error as the mean of the MSE of each node. A way that, at first glance, could seem reasonable, but, actually, it is not: such MSE is not computed with one weight vector over the entire training set, indeed if someone asked for the weight vector which had produced such result, then we would not have a value to provide they with.\n",
    "That's why the correct way to compute the global metrics is to retrieve from each node $k$ its local model $\\vec{w}_{k}$, compute the global model $\\vec{w} = \\frac{1}{K}\\sum_{k=1}^{K}\\vec{w}_k$ and then compute metrics taking into account $\\vec{w}$ along with the whole training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test description\n",
    "Since there are several parameters to set up in order to run a test, I have excluded to pass them from the command line (by running the program in a way like `$ python main.py [parameters]`), instead they're are set directly inside the script `main.py`. Leave aside for a while the system and training task setup, there are many other settings which ensure control over the test's execution and outputs. Without deepening their implementation, when a new test is run, the simulator creates a new folder `/$TEST_NAME` in `/test_log` that contains:\n",
    "- a `/plot` folder with all plots images;\n",
    "- all global logs of the simulation for each topology;\n",
    "- a descriptor file that reports the detailed parameters' values used for the test;\n",
    "- a serialization of the setup that can be used to run again the same simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a test folder tree**.\n",
    "```\n",
    "./test_log\n",
    "└── /$TEST_NAME\n",
    "    ├── /plot\n",
    "    │   ├── iter_time.png\n",
    "    │   ├── mse_iter.png\n",
    "    │   ├── mse_time.png\n",
    "    │   ├── real-mse_iter.png\n",
    "    │   └── real-mse_time.png\n",
    "    ├── clique_global_mean_squared_error_log\n",
    "    ├── clique_global_real_mean_squared_error_log\n",
    "    ├── clique_iterations_time_log\n",
    "    ├── cycle_global_mean_squared_error_log\n",
    "    ├── cycle_global_real_mean_squared_error_log\n",
    "    ├── cycle_iterations_time_log\n",
    "    ├── diagonal_global_mean_squared_error_log\n",
    "    ├── diagonal_global_real_mean_squared_error_log\n",
    "    ├── diagonal_iterations_time_log\n",
    "    ├── diam-expander_global_mean_squared_error_log\n",
    "    ├── diam-expander_global_real_mean_squared_error_log\n",
    "    ├── diam-expander_iterations_time_log\n",
    "    ├── root-expander_global_mean_squared_error_log\n",
    "    ├── root-expander_global_real_mean_squared_error_log\n",
    "    ├── root-expander_iterations_time_log\n",
    "    ├── .descriptor.txt\n",
    "    └── .setup.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test descriptor file `.descriptor.txt`\n",
    "Below how the descriptor appears. Although each parameter is provided with a short description embedded within a comment, it doesn't matter if some or most of them won't be immediately understandable, however simply take a fast look at this code snippet to realize how many parameters the system let us customize. Remind that such **descriptor file is auto-generated** right after a test has started.\n",
    "\n",
    "```python\n",
    "# >>> Test Descriptor File\n",
    "Title: 'test'\n",
    "Date: '2018-04-26 11:28:39.116108'\n",
    "Summary: '-'\n",
    "\n",
    "### BEGIN SETUP ###\n",
    "n = 10  # amount of computational nodes\n",
    "seed = 1524734919  # random initial seed\n",
    "\n",
    "# adjacency matrices for each graph\n",
    "graphs = {\n",
    "    'clique': np.array([\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
    "    'cycle': np.array([\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'diagonal': np.array([\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'diam-expander': np.array([\n",
    "        [1., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "        [1., 1., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [0., 1., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
    "        [0., 0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
    "        [1., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
    "        [0., 0., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
    "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]]),\n",
    "    'root-expander': np.array([\n",
    "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
    "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
    "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'star': np.array([\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "    )}\n",
    "\n",
    "# TRAINING SET SETUP\n",
    "n_samples = 100000\n",
    "n_features = 100\n",
    "\n",
    "# function used to generate the training set\n",
    "sample_function = <function LinearYHatFunction.f at 0x7f13fa4d00d0>\n",
    "domain_radius = 5\n",
    "domain_center = 0\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "\n",
    "# CLUSTER SETUP\n",
    "max_iter = None  # upon reaching max_iter iterations the cluster will stop\n",
    "max_time = 100000  # the same for the time \n",
    "yhat = <class 'src.mltoolbox.LinearYHatFunction'>  # function to learn the parameters of\n",
    "method = 'stochastic'\n",
    "batch_size = 20  # matters only for the batch gradient method\n",
    "activation_func = None  # to specify for classification training task for instance\n",
    "loss = <class 'src.mltoolbox.SquaredLossFunction'>  # loss function\n",
    "penalty = 'l2'  # not used yet\n",
    "epsilon = 0.01  # error goodness threshold\n",
    "alpha = 1e-06  # alpha constant\n",
    "learning_rate = 'constant'  # type of learning rate, not used yet\n",
    "metrics = 'all'  # specify which metrics the system may take into account\n",
    "alt_metrics = False  # if True then the MSE will be computed as it happened earlier\n",
    "shuffle = True  # whether the cluster should shuffle the training set\n",
    "verbose = False  # not used yet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation useful informations\n",
    "In this section are listed some useful details in order to doubtless understand further simulation outputs.\n",
    "\n",
    "## Meaning of _iteration_\n",
    "Each node owns a local field `iteration`. The starting value is 0. Actually \"iteration equal to $t$\" means that the weight vector has been updated $t$ times. A single update of the weight $w_{t+i} = w_t - \\alpha \\nabla Err$ implies the iteration to increase by one from $t$ to $t+1$.\n",
    "- \"Node $i$ is at iteration $t$\" means it has already computed the $t$-th step of the gradient descent method, thus $w_t$ is its the most recent weight vector owned by $i$.\n",
    "- \"Node $i$ computes/performs iteration $t$\" means that $i$ is performing the update $w_{t} = w_{t-1} - \\alpha \\nabla Err$.\n",
    "\n",
    "The _cluster_ model (the object that supervises the distributed simulation) has an `iteration` field too, it is equal to the fewest iteration among all nodes. `cluster.iteration` being equal to $t$ means that each node has already performed at least $t$ updates of its local $w_t$ but at least one node has not computed $w_{t+1}$ yet, thus a global $w_t$ can be retrieved (and used to compute metrics for instance).\n",
    "\n",
    "## Single iteration time\n",
    "> **`time.perf_counter()`**\n",
    "\n",
    "> Return the value (in fractional seconds) of a performance counter, i.e. a clock with the highest available resolution to measure a short duration. It does include time elapsed during sleep and is **system-wide**. The reference point of the returned value is undefined, so that only the difference between the results of consecutive calls is valid.\n",
    "\n",
    "> *(from the [Python Standard Library Documentation](https://docs.python.org/3/library/time.html#time.perf_counter))*\n",
    "\n",
    "`time.perf_counter()` is the value Python developers suggest to use in order to make performance evaluation of python algorithms, but, obviously, since it is taken directly from the processor, it is *system-wide*, thus depends on too many unknown and unmanageable variable conditions (i.e. other system processes, OS processes' managing system, etc.).\n",
    "\n",
    "It's clear why the time taken by a node to perform a single iteration computation (e.g. gradient descent weights update) cannot be retrieved considering such clock, so the function below isn't reliable at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def unreliable_gradient_step(self):\n",
    "    \"\"\"\n",
    "    Perform a single step of the gradient descent method.\n",
    "    :return: a list containing [clock_before, clock_after] w.r.t. the computation\n",
    "    \"\"\"\n",
    "    # useful vars for estimate the time taken by the computation\n",
    "    t0 = self.local_clock\n",
    "    # get the processor time counter before the computation starts\n",
    "    c0 = time.perf_counter()\n",
    "\n",
    "    ## STEP COMPUTATION BEGIN\n",
    "    # avg internal self.W vector with W incoming from dependencies\n",
    "    if self.iteration > 0:\n",
    "        self.avg_weight_with_dependencies()\n",
    "    # compute the gradient descent step\n",
    "    self.training_task.step()\n",
    "    # broadcast the obtained value to all node's recipients\n",
    "    self.broadcast_weight_to_recipients()\n",
    "    ## STEP COMPUTATION END\n",
    "        \n",
    "    # get the processor counter after the computation has ended\n",
    "    cf = time.perf_counter()\n",
    "    # computes the clock when the computation has finished\n",
    "    tf = t0 + cf - c0\n",
    "        \n",
    "    # update the local_clock\n",
    "    self.local_clock = tf\n",
    "    self.iteration += 1\n",
    "\n",
    "    return [t0, tf]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead it is more convenient and reasonable to consider the following function:\n",
    "\n",
    "```python\n",
    "def reliable_gradient_step(self):\n",
    "    \"\"\"\n",
    "    Perform a single step of the gradient descent method.\n",
    "    :return: a list containing [clock_before, clock_after] w.r.t. the computation\n",
    "    \"\"\"\n",
    "    # useful vars for estimate the time taken by the computation\n",
    "    t0 = self.local_clock\n",
    "\n",
    "    # avg internal self.W vector with W incoming from dependencies\n",
    "    if self.iteration > 0:\n",
    "        self.avg_weight_with_dependencies()\n",
    "\n",
    "    # compute the gradient descent step\n",
    "    self.training_task.step()\n",
    "\n",
    "    # broadcast the obtained value to all node's recipients\n",
    "    self.broadcast_weight_to_recipients()\n",
    "\n",
    "    # get the counter after the computation has ended\n",
    "    # get the time from an exponential with lambda parameter equal to 1\n",
    "    # whereas lambda = 1 / mean_time, so mean_time = 1\n",
    "    dt = random.expovariate(1)\n",
    "\n",
    "    # computes the clock when the computation has finished\n",
    "    tf = t0 + dt\n",
    "    # update the local_clock\n",
    "    self.local_clock = tf\n",
    "\n",
    "    self.iteration += 1\n",
    "    self.log.append(self.local_clock)\n",
    "\n",
    "    return [t0, tf]\n",
    "```\n",
    "\n",
    "The time taken by a node to perform a single gradient step is handled by a random variable $X \\sim Exp(\\lambda)$ (e.g. exponentially distributed with parameter $\\lambda$) where $\\mathbb{E}[X] = \\frac{1}{\\lambda}$. At the moment $\\lambda$ is fixed to $1$, so, in this case, the mean time is equal to one too.\n",
    "\n",
    "_It is not mandatory for you to know more details about how the system actually works._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous tests - 002 (those made until 25/04/18)\n",
    "Outdated, not reported here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New tests - 003 (since 26/04/18)\n",
    "## Main changes from earlier tests\n",
    "1. The number of computational units has been fixed to $n=10$;\n",
    "2. `diam-expander` has lost one edge per node. It is now defined as\n",
    "    $$G=(V=\\{0,...n-1\\},E=\\{(i, i+1\\text{ mod }n), (i, i+\\frac{n}{2}\\text{ mod }n) : i \\in [n]\\});$$\n",
    "    \n",
    "    **Example of a diameter expander with 6 nodes.**\n",
    "    \n",
    "    ![Diam-expander graph](media/img/graph-samples/diam-expander.png)\n",
    "3. a new dependency graph `root-expander` has been considered\n",
    "    $$G=(V=\\{0,...n-1\\},E=\\{(i, i+1\\text{ mod }n), (i, i+\\sqrt{n}\\text{ mod }n) : i \\in [n]\\});$$\n",
    "    \n",
    "    **Example of a root expander with 6 nodes.**\n",
    "    \n",
    "    ![Root-expander graph](media/img/graph-samples/root-expander.png)\n",
    "4. at the moment we will focus on testing the classic GD method. Right after obtaining some results for GD, we will test BGD (batch gradient descent) and SGD (stochastic gradient descent) as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant tests fixed parameters\n",
    "```python\n",
    "n = 10\n",
    "seed = str(time.time()) # timestamp\n",
    "graphs = {\n",
    "    # cycle, clique, root-expander, diam-expander, diagonal adjacency matrices\n",
    "}\n",
    "\n",
    "# TRAINING SET SETUP\n",
    "n_features = 100\n",
    "yhat = <class 'src.mltoolbox.LinearYHatFunction'>\n",
    "domain_radius = 5\n",
    "domain_center = 0\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "\n",
    "# CLUSTER SETUP\n",
    "sample_function = <function LinearYHatFunction.f at 0x7f13fa4d00d0>\n",
    "max_iter = None\n",
    "max_time = 10000\n",
    "method = 'classic'\n",
    "loss = <class 'src.mltoolbox.SquaredLossFunction'>\n",
    "penalty = l2\n",
    "epsilon = 0.01\n",
    "alpha = 1e-06\n",
    "learning_rate = constant\n",
    "metrics = all\n",
    "alt_metrics = False\n",
    "shuffle = True\n",
    "verbose = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter we will focus particularly on and the only which will vary is `n_samples`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 samples GD test\n",
    "`n_samples = 100`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 sample GD test - Iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100samples_classic/1_iter_time.png)\n",
    "This trend will be a constant through all future tests: the less the nodes' connections the fastest the system can advance in iterations.\n",
    "\n",
    "As expected, in diagonal topology, since nodes never wait still and since the mean of the time taken by each iteration is equal to 1, then such topology always achieves an amount of iterations approximately equal to the time of the simulation. This plot makes us notice that the amount of iteration achieved by each topology depends, in some way, on the graph's degree (e.g. number of dependency established among nodes). Further, we would like to study in depth this intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 sample GD test - MSE over iterations\n",
    "![MSE over iter](media/img/tests/test_003_100samples_classic/2_mse_iter.png)\n",
    "Due to restricted training set size, a single node doesn't own enough samples to achieve a good model without communicating with other nodes, therefore diagonal topology performs far worse than the others, which in turn behave almost equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - RMSE over iterations\n",
    "![RMSE over iter](media/img/tests/test_003_100samples_classic/2_real-mse_iter.png)\n",
    "RMSE/iter plot doesn't suggest anything more than MSE/iter already does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100samples_classic/3_mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100samples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_100samples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "As already seen in previous plots for this test, diagonal topology, unlike all the others, never achieves a good prediction model. \n",
    "\n",
    "The cycle turns out to be the fastest.\n",
    "\n",
    "2-degree graphs plots (root expander and diameter expander) are very close.\n",
    "\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1k samples GD test\n",
    "`n_samples = 1000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_1ksamples_classic/1_iter_time.png)\n",
    "Almost the same result as in 100 samples test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_classic/2_mse_iter.png)\n",
    "![MSE over iterations zoom](media/img/tests/test_003_1ksamples_classic/2_mse_iter_zoom.png)\n",
    "\n",
    "Now, since the amount of samples in the training set is equal to 1000, each node $i$ owns a subsample $\\mathcal{X}_i \\subset \\mathcal{X}$ such that $|\\mathcal{X}_i| = 100$ (when for $|\\mathcal{X}|=100$, $|\\mathcal{X}_i|=10$). Such condition seems enough for the diagonal topology to perform similarly as those with communications among nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_1ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_1ksamples_classic/2_real-mse_iter_zoom.png)\n",
    "By comparing MSE/iter and RMSE/iter, we notice that diagonal topology suffers noise more than other topologies do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_1ksamples_classic/3_mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_1ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "Despite the behaviour of topologies, with respect to **convergence speed**, is almost the same as the one observed in the _100 samples test MSE/time plot_, now diagonal topology doesn't behave so bad anymore (its error differs only by 1 from other topologies). \n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10k samples test\n",
    "`n_samples = 10000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_10ksamples_classic/1_iter_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_10ksamples_classic/2_mse_iter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_10ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_10ksamples_classic/2_real-mse_iter_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_10ksamples_classic/3_mse_time.png)\n",
    "![MSE over time_zoom](media/img/tests/test_003_10ksamples_classic/3_mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_10ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_10ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "With $10000$ samples diagonal outperforms other topologies with regard to either MSE/time and RMSE/time plots.\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100k samples GD test\n",
    "`n_samples = 100000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100ksamples_classic/1_iter_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_100ksamples_classic/2_mse_iter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_100ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_100ksamples_classic/2_real-mse_iter_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100ksamples_classic/3_mse_time.png)\n",
    "![MSE over time_zoom](media/img/tests/test_003_100ksamples_classic/3_mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_100ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training set gets bigger, diagonal topology turns out to be by far the fastest. I would like to make some tests with different kinds of training sets to assess whether this results are strongly related to this training set morphology or can be extended to more general cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Below tests with 100 and 1000 samples repeated with `method='stochastic'` instead of `classic` for the gradient descent.\n",
    "\n",
    "## 100 samples SGD test\n",
    "\n",
    "### 100 samples SGD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100samples_stochastic/1_iter_time.png)\n",
    "\n",
    "### 100 samples SGD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_100samples_stochastic/2_mse_iter.png)\n",
    "![MSE over iterations](media/img/tests/test_003_100samples_stochastic/2_mse_iter_zoom.png)\n",
    "\n",
    "### 100 samples SGD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_100samples_stochastic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_100samples_stochastic/2_real-mse_iter_zoom.png)\n",
    "\n",
    "### 100 samples SGD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100samples_stochastic/3_mse_time.png)\n",
    "\n",
    "### 100 samples SGD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100samples_stochastic/3_real-mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1k samples SGD test\n",
    "\n",
    "### 1k samples SGD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_1ksamples_stochastic/1_iter_time.png)\n",
    "\n",
    "### 1k samples SGD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_mse_iter.png)\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_mse_iter_zoom.png)\n",
    "\n",
    "### 1k samples SGD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_1ksamples_stochastic/2_real-mse_iter_zoom.png)\n",
    "\n",
    "### 1k samples SGD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_1ksamples_stochastic/3_mse_time.png)\n",
    "\n",
    "### 1k samples SGD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_stochastic/3_real-mse_time.png)\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_stochastic/3_real-mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical point of view\n",
    "### Nodes' degree\n",
    "We've noticed that the iterations' speed is strongly related to the number of connections established among nodes, this is clearly observable in all _iteration over time_ plots. A similar speed gain can be seen in _MSE over time_ plot: whether the amount of samples in the training set is big enough such that even a single node alone can achieve a good solution, then connections are just cause of slowdown. It seems that the gain in iterations' speed always matters far more than the gain in information flow due to an high dependency graph's degree. This is only a suggestion given by these early tests.\n",
    "\n",
    "Now let's consider the following plot (_MSE over time 10k samples GD test 003_).\n",
    "\n",
    "![MSE_over_time](media/img/tests/test_003_10ksamples_classic/3_mse_time_big.png)\n",
    "\n",
    "By inverting it we obtain the plot below. _NB: actually such functions aren't invertible since in small intervals the error can oscillate, anyway fixes can be applied to make them invertible (like exploiting a moving average)._\n",
    "\n",
    "![Time over MSE](media/img/tests/test_003_10ksamples_classic/4_time_mse_big.png)\n",
    "\n",
    "We can compare the time taken by each topology to achieve a same value of MSE, then effectively estimate the speed ratio among different topologies. The same will be done for RMSE/time, MSE/iter and RMSE/iter plots too. _This comparison will be included in the next report._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependency graph's diameter\n",
    "Assume all nodes in the system being at iteration $r>0$, assume that one node $s$ gets stuck there (it never advances to iteration $r+1$), then:\n",
    "- nodes at distance 1 from $s$ can advance only by one more iteration;\n",
    "- nodes at distance 2 from $s$ can advance only by two more iterations;\n",
    "- and so on, up to nodes at distance $d_s$ from $s$ (where $d_s = max\\{dist(s, i) : i \\in V\\}$) that can advance by $d_s$ more iterations.\n",
    "\n",
    "In general:\n",
    "$$\n",
    "\\forall i,j \\in V,\\ i \\text{ is at iteration }r \\Rightarrow j \\text{ is at iteration} \\in [r-dist(i,j),r+dist(i,j)] \\subseteq \\mathbb{N}.\n",
    "$$\n",
    "\n",
    "Since $\\forall i,j \\in V,\\ dist(i,j) \\leq diam$ (where $diam$ is the graph's diameter), then the maximum distance between two nodes, with respect to iterations' number, is always less than or equal to the graph diameter. Even this property seems to be a key factor in speed gain.\n",
    "\n",
    "For instance, the following inequality\n",
    "$$diam(\\text{clique}) = 1 < diam(\\text{diam-expander}) = \\frac{n}{2} < diam(\\text{cycle}) = n-1$$\n",
    "holds also for the speed: the cycle is faster than the diam-expander which in turn is faster than the clique.\n",
    "\n",
    "The questions now I am looking an answer for are:\n",
    "1. How the speed is related to the nodes' degree?\n",
    "2. How the speed is related to graph's diameter?\n",
    "3. How much do degree and diameter weight in the observed topologies' speed? e.g. which matters more?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System dynamic\n",
    "Let $r \\geq 0$ be a fixed iteration number. Let $X_1, X_2, ..., X_n$ be $n$ independent random variables where $X_i$ is the time taken by node $i$ to advance to iteration $r+1$. At the moment we consider $X_i \\sim Exp(\\lambda = 1)$, so\n",
    "- $P(X_i \\leq t) = 1-e^{-\\lambda t} = 1-e^{-t}$, hence $P(X_i > t) = e^{-\\lambda t} = e^{-t}$.\n",
    "- $\\mathbb{E}[X_i] = \\frac{1}{\\lambda} = 1$.\n",
    "\n",
    "Lets define a new random variable $Z = max\\{X_i : 1 \\leq i \\leq n\\}$. $Z$ is the time taken by the slowest node to complete the $(r+1)$-th update of its weight vector, where:\n",
    "- $P(Z \\leq z) = \\prod_{i=1}^{n} P(X_i \\leq z) = (1-e^{-t})^n$;\n",
    "- $\\mathbb{E}[Z] = \\frac{1}{\\lambda} \\sum_{i=1}^{n} \\frac{1}{i}$.\n",
    "\n",
    "\n",
    "$Z$ reflects the time taken by the slowest node to perform the $(r+1)$-th weight update.\n",
    "\n",
    "It is easy to exploit $Z$ to analyze the clique behaviour since $Z$ is exactly the time taken by each node to perform the $(r+1)$-th update of its weight. For other topologies it is not so trivial. Anyway, this is the way I will follow to give significance from a theoretical point of view to results. _Further considerations will be provided in the next report._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteration speed lower bound\n",
    "Let $k$ be the degree of a regular dependency graph $G$. $V_l$ is the velocity lower bound in terms of iterations per node and per time, so the unit of measurement is $\\frac{\\text{# iterations}}{\\text{time}}$.\n",
    "\n",
    "In the worst case the node most advanced in the computation will need to wait for all its neighbours and only then it can start a new iteration.\n",
    "\n",
    "In such case, if computations are I.I.D (independent and identically distributed) exponentials $X_1, X_2, ..., X_n$ with parameter $\\lambda$, the mean time $$T_l$$ each node have to wait is\n",
    "\n",
    "$$T = \\mathbb{E}[Z] = \\frac{1}{\\lambda}\\sum_{i=1}^{k} \\frac{1}{i}$$.\n",
    "\n",
    "The per-node iteration rate (e.g. the speed to perform a single iteration step) will be\n",
    "\n",
    "$$V = \\frac{1}{T} = \\frac{\\lambda}{\\sum_{i=1}^{k}\\frac{1}{i}}$$\n",
    "\n",
    "so\n",
    "\n",
    "$$V_l = \\frac{\\lambda}{1+\\sum_{i=1}^{k}\\frac{1}{i}} \\sim \\frac{\\lambda}{\\ln k} \\text{ for large } k$$\n",
    "\n",
    "is a lower bound for $V$.\n",
    "\n",
    "#### Comparison with exact calculations for the clique ($k=n-1$)\n",
    "\n",
    "$$V = \\frac{\\lambda}{\\sum_{i=1}^{k}\\frac{1}{i}} > \\frac{\\lambda}{1+\\sum_{i=1}^{n-1}\\frac{1}{i}} = V_l$$\n",
    "\n",
    "#### Why is it a lower bound for $k=1$\n",
    "![Example](media/img/graph-samples/iter-speed-lb-example.png)\n",
    "\n",
    "`a` is the most advanced node (e.g. `a.iteration` $>$ `b.iteration` and `a.iteration` $>$ `c.iteration`), so it is waiting for `b` to finish its calculations, but actually `b` already got the required input from `c`, then, as soon as `b` finishes with the current computation, both `a` and `b` can move to compute to the next step. Then the next iteration will be computed by the most advanced node (it can be either `a` or `b`) after $\\frac{1}{\\lambda} + \\frac{1}{2 \\lambda}$ and not after $\\frac{1}{\\lambda} + \\frac{1}{\\lambda}$ as considered by the lower bound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
