{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joint conf-call report #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-27 18:31:57.048852\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(str(datetime.datetime.today()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_For this second report I am experimenting a new way to fastly deploy updates about the project: **Jupyter notebook**. In this stage of the project, I'd like to share more code snippets than I would in the final thesis, hence markdown support and live execution of code snippets turned out to be very useful for such purpose. Actually the two main reason why I decided to move from raw LaTeX to here are: (1) Jupyter does it faster, (2) it converts everything to LaTeX (I won't be required to make any effort to include everything from here to my LaTeX thesis document). Whether, for any reason, this method will turn out to be ineffective or time-expensive, then I will drop it out._\n",
    "\n",
    "_You will notice changes in style, format and even contents (like change logs and other stuffs that may appear useless or too much detailed), this necessity arises since I need to keep track of the internship's history and I foresee that within few months the commit log on Github will get a bit messy and too much wide to be relied on, instead these reports are the easiest way to fulfill such task._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change log summary\n",
    "\n",
    "## Training set generator function\n",
    "Now domains of all samples' components are centered at the same value $c$. Such domains are determined as follows.\n",
    "\n",
    "Is defined $K = \\{k_1,...k_m\\}$ where $k_i$ is the domain radius of variable $x_i$.\n",
    "Let $x=(x_1,...,x_m) \\in X$ be a sample of the training set, then the domain of $x_i$ is $D(x_i) = [c-k_i, c+k_i]$.\n",
    "\n",
    "\n",
    "```python\n",
    "def sample_from_function(n_samples, n_features, func, domain_radius=0.5, domain_center=0.5,error_mean=0, error_std_dev=1):\n",
    "    X = []\n",
    "    y = np.zeros(n_samples)\n",
    "    w = np.ones(n_features)\n",
    "    K = np.random.uniform(domain_center - domain_radius, domain_center + domain_radius, n_features)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        x = np.zeros(n_features)\n",
    "        for j in range(n_features):\n",
    "            x[j] = np.random.uniform(-K[j] + domain_radius, K[j] + domain_radius)\n",
    "        X.append(x)\n",
    "        y[i] = func(x, w) + np.random.normal(error_mean, error_std_dev)\n",
    "\n",
    "return np.array(X), y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**. Detailed execution of `sample_from_function` with the following parameters:\n",
    "- `n_samples = 8` : amount of samples in the training set;\n",
    "- `n_features = 4` : number of features, e.g. size of each array sample;\n",
    "- `func` : classic linear function $f(\\vec{x},\\vec{w})=\\sum_{j=1}^{m} x_j w_j$ where $m$ is the size of $x$ (and $w$), so, for instance, $f((2,3),(4,1))=2*4+3*1=11$;\n",
    "- `domain_radius = 5`;\n",
    "- `domain_center = 0`;\n",
    "- `error_mean = 0`;\n",
    "- `error_std_dev = 1`: the error (noise) follows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "n_samples = 8\n",
    "n_features = 4\n",
    "func = lambda _X,_w : _X.dot(_w)\n",
    "domain_center = 0\n",
    "domain_radius = 5\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "X = []\n",
    "y = np.zeros(n_samples)\n",
    "w = np.ones(n_features)\n",
    "K = np.random.uniform(domain_center - domain_radius, domain_center + domain_radius, n_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$K = \\{k_1,...k_m\\}$ where $k_i$ is the domain radius of variable $x_i$, so the domain of $x_i$ will be $D(x_i) = [c-k_i, c+k_i]$ where $c$ is the center of the domain (`domain_center`); $c$ is the same for all $x_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.52119871 -3.49339253  0.78825275  1.94900492]\n"
     ]
    }
   ],
   "source": [
    "print(K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = \n",
      "[   array([5.37854823, 6.8805404 , 5.43863273, 3.70761341]),\n",
      "    array([4.49876408, 2.0503524 , 5.65447532, 6.20513672]),\n",
      "    array([4.7763755 , 7.60097235, 5.62906949, 5.31611178]),\n",
      "    array([4.59133688, 5.72168759, 5.48712864, 3.28391611]),\n",
      "    array([4.83257145, 4.94455571, 5.67025303, 4.35290562]),\n",
      "    array([5.25725052, 2.20889856, 4.75665919, 4.15219002]),\n",
      "    array([4.85474965, 7.61454419, 5.46424491, 3.31427248]),\n",
      "    array([4.65061106, 7.88019238, 4.36332698, 5.52285168])]\n",
      "y = array([21.77131617, 19.64347611, 22.27622461, 19.84065106, 19.86289585,\n",
      "       16.94266059, 21.20252347, 22.50855809])\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_samples):\n",
    "    x = np.zeros(n_features)\n",
    "    for j in range(n_features):\n",
    "        x[j] = np.random.uniform(-K[j] + domain_radius, K[j] + domain_radius)\n",
    "    X.append(x)\n",
    "    y[i] = func(x, w) + np.random.normal(error_mean, error_std_dev)\n",
    "print(\"X = \\n\" + pprint.PrettyPrinter(indent=4).pformat(X))\n",
    "print(\"y = \" + pprint.PrettyPrinter(indent=4).pformat(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New metric Real Mean Squared Error (RMSE)\n",
    "The training set is in the form of a pair $(X,y)$ where $y_i$ is the value the target function is supposed to yield for the input $x_i$, actually, whether a noise exists in the training set, then $y_i$ differs from the real value $\\tilde{y}_i$ by a gap that, in our case, is normally distributed (with mean = `error_mean` and standard deviation = `error_std_dev`). Whereas the training set is generated with fully control over all parameters, we know either the perturbed value $y_i$ either the real value $\\tilde{y}_i=\\mathbb{1} x_i=\\sum_{j=1}^{m}x_{ij}$, so we have an additional information to take into account in order to study the behaviour of different models.\n",
    "\n",
    "While the mean squared error\n",
    "$$MSE = \\frac{1}{N} \\sum_{i=1}^{n} (y_i - \\hat{y}_i) (\\hat{y}_i)'$$\n",
    "regards $y_i$, the real MSE concerns $\\tilde{y}_i$, hence it's defined as\n",
    "$$RMSE = \\frac{1}{N} \\sum_{i=1}^{n} (\\tilde{y}_i - \\hat{y}_i) (\\hat{y}_i)'.$$\n",
    "\n",
    "By comparing these two metrics one can understand whether and how much the prediction model suffers from noise fitting, e.g. when the model adapts itself much more on the noise rather than on the provided target function value.\n",
    "\n",
    "Obviously, noiseless training sets lead the MSE to be equal to the RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the error over the whole training set\n",
    "After each iteration each node computes a set of metrics taking into account its local model and knowledge, so each node keeps track of the history of its weight vector, MAE (mean absolute error), RMAE (to be implemented yet), MSE, RMSE.\n",
    "\n",
    "Previously I computed the error as the mean of the MSE of each node. A way that, at first glance, could seem reasonable, but, actually, it is not: such MSE is not computed with one weight vector over the entire training set, indeed if someone asked for the weight vector which had produced such result, then we would not have a value to provide they with.\n",
    "That's why the correct way to compute the global metrics is to retrieve from each node $k$ its local model $\\vec{w}_{k}$, compute $\\vec{w} = \\frac{1}{K}\\sum_{k=1}^{K}\\vec{w}_k$ and then compute metrics taking into account $\\vec{w}$ along with the whole training set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test description\n",
    "Since there are several parameters to set up in order to run a test, I have excluded to pass them from the command line (by running the program in a way like `$ python main.py [parameters]`), instead they're are set directly inside the script `main.py`. Leave aside for a while the system and training task setup, there are many other settings which ensure control over the test's execution and outputs. Without deepening their implementation, when a new test is run, the simulator creates a new folder `/$TEST_NAME` in `/test_log` that contains:\n",
    "- a `/plot` folder with all plots images;\n",
    "- all global logs of the simulation for each topology;\n",
    "- the descriptor file that reports the detailed parameters' values used for the test;\n",
    "- a serialization of the setup that can be used to run again the same simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example of a test folder tree**.\n",
    "```\n",
    "./test_log\n",
    "└── /$TEST_NAME\n",
    "    ├── /plot\n",
    "    │   ├── iter_time.png\n",
    "    │   ├── mse_iter.png\n",
    "    │   ├── mse_time.png\n",
    "    │   ├── real-mse_iter.png\n",
    "    │   └── real-mse_time.png\n",
    "    ├── clique_global_mean_squared_error_log\n",
    "    ├── clique_global_real_mean_squared_error_log\n",
    "    ├── clique_iterations_time_log\n",
    "    ├── cycle_global_mean_squared_error_log\n",
    "    ├── cycle_global_real_mean_squared_error_log\n",
    "    ├── cycle_iterations_time_log\n",
    "    ├── diagonal_global_mean_squared_error_log\n",
    "    ├── diagonal_global_real_mean_squared_error_log\n",
    "    ├── diagonal_iterations_time_log\n",
    "    ├── diam-expander_global_mean_squared_error_log\n",
    "    ├── diam-expander_global_real_mean_squared_error_log\n",
    "    ├── diam-expander_iterations_time_log\n",
    "    ├── root-expander_global_mean_squared_error_log\n",
    "    ├── root-expander_global_real_mean_squared_error_log\n",
    "    ├── root-expander_iterations_time_log\n",
    "    ├── .descriptor.txt\n",
    "    └── .setup.pkl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test descriptor file `.descriptor.txt`\n",
    "Below is how the descriptor appears. Although each parameter is provided with a short description embedded within a comment, it doesn't matter if some or most of them won't be immediately understandable, however simply take a fast look at this code snippet to realize how many parameters the system let us customize. Remind that the **descriptor file is auto-generated** right after a test has started.\n",
    "\n",
    "```python\n",
    "# >>> Test Descriptor File\n",
    "Title: 'test'\n",
    "Date: '2018-04-26 11:28:39.116108'\n",
    "Summary: '-'\n",
    "\n",
    "### BEGIN SETUP ###\n",
    "n = 10  # amount of computational nodes\n",
    "seed = 1524734919  # random initial seed\n",
    "\n",
    "# adjacency matrices for each graph\n",
    "graphs = {\n",
    "    'clique': np.array([\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
    "    'cycle': np.array([\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'diagonal': np.array([\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'diam-expander': np.array([\n",
    "        [1., 1., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
    "        [1., 1., 1., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [0., 1., 1., 1., 0., 0., 0., 1., 0., 0.],\n",
    "        [0., 0., 1., 1., 1., 0., 0., 0., 1., 0.],\n",
    "        [0., 0., 0., 1., 1., 1., 0., 0., 0., 1.],\n",
    "        [1., 0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
    "        [0., 1., 0., 0., 0., 1., 1., 1., 0., 0.],\n",
    "        [0., 0., 1., 0., 0., 0., 1., 1., 1., 0.],\n",
    "        [0., 0., 0., 1., 0., 0., 0., 1., 1., 1.],\n",
    "        [1., 0., 0., 0., 1., 0., 0., 0., 1., 1.]]),\n",
    "    'root-expander': np.array([\n",
    "        [1., 1., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [0., 1., 1., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [0., 0., 1., 1., 0., 1., 0., 0., 0., 0.],\n",
    "        [0., 0., 0., 1., 1., 0., 1., 0., 0., 0.],\n",
    "        [0., 0., 0., 0., 1., 1., 0., 1., 0., 0.],\n",
    "        [0., 0., 0., 0., 0., 1., 1., 0., 1., 0.],\n",
    "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
    "        [0., 1., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
    "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 1.]]),\n",
    "    'star': np.array([\n",
    "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
    "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
    "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]\n",
    "    )}\n",
    "\n",
    "# TRAINING SET SETUP\n",
    "n_samples = 100000\n",
    "n_features = 100\n",
    "\n",
    "# function used to generate the training set\n",
    "sample_function = <function LinearYHatFunction.f at 0x7f13fa4d00d0>\n",
    "domain_radius = 5\n",
    "domain_center = 0\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "\n",
    "# CLUSTER SETUP\n",
    "max_iter = None  # upon reaching max_iter iterations the cluster will stop\n",
    "max_time = 100000  # the same for the time \n",
    "yhat = <class 'src.mltoolbox.LinearYHatFunction'>  # function to learn the parameters of\n",
    "method = 'stochastic'\n",
    "batch_size = 20  # matters only for the batch gradient method\n",
    "activation_func = None  # to specify for classification training task for instance\n",
    "loss = <class 'src.mltoolbox.SquaredLossFunction'>  # loss function\n",
    "penalty = 'l2'  # not used yet\n",
    "epsilon = 0.01  # error goodness threshold\n",
    "alpha = 1e-06  # alpha constant\n",
    "learning_rate = 'constant'  # type of learning rate, not used yet\n",
    "metrics = 'all'  # specify which metrics the system may take into account\n",
    "alt_metrics = False  # if True then the MSE will be computed as it happened earlier\n",
    "shuffle = True  # whether the cluster should shuffle the training set\n",
    "verbose = False  # not used yet\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation ???\n",
    "In this section are listed some useful details in order to doubtless understand further simulation outputs.\n",
    "\n",
    "## Single iteration time\n",
    "> **`time.perf_counter()`**\n",
    "\n",
    "> Return the value (in fractional seconds) of a performance counter, i.e. a clock with the highest available resolution to measure a short duration. It does include time elapsed during sleep and is **system-wide**. The reference point of the returned value is undefined, so that only the difference between the results of consecutive calls is valid.\n",
    "\n",
    "> *(from the [Python Standard Library Documentation](https://docs.python.org/3/library/time.html#time.perf_counter))*\n",
    "\n",
    "`time.perf_counter()` is the value Python developers suggest to use to make performance evaluation of python algorithms, but, obviously, since it is taken directly from the processor, it is *system-wide*, thus depends on too many unknown and unmanageable variable conditions (i.e. other system processes, OS processes' managing system, etc.).\n",
    "\n",
    "It's now clear that the time taken by a node to perform a single iteration computation (e.g. gradient descent weights update) cannot be computed considering such clock, so the function below isn't reliable at all:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def unreliable_gradient_step(self):\n",
    "    \"\"\"\n",
    "    Perform a single step of the gradient descent method.\n",
    "    :return: a list containing [clock_before, clock_after] w.r.t. the computation\n",
    "    \"\"\"\n",
    "    # useful vars for estimate the time taken by the computation\n",
    "    t0 = self.local_clock\n",
    "    # get the processor time counter before the computation starts\n",
    "    c0 = time.perf_counter()\n",
    "\n",
    "    ## STEP COMPUTATION BEGIN\n",
    "    # avg internal self.W vector with W incoming from dependencies\n",
    "    if self.iteration > 0:\n",
    "        self.avg_weight_with_dependencies()\n",
    "    # compute the gradient descent step\n",
    "    self.training_task.step()\n",
    "    # broadcast the obtained value to all node's recipients\n",
    "    self.broadcast_weight_to_recipients()\n",
    "    ## STEP COMPUTATION END\n",
    "        \n",
    "    # get the processor counter after the computation has ended\n",
    "    cf = time.perf_counter()\n",
    "    # computes the clock when the computation has finished\n",
    "    tf = t0 + cf - c0\n",
    "        \n",
    "    # update the local_clock\n",
    "    self.local_clock = tf\n",
    "    self.iteration += 1\n",
    "\n",
    "    return [t0, tf]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead it is more convenient and reasonable to consider the following function:\n",
    "\n",
    "```python\n",
    "def reliable_gradient_step(self):\n",
    "    \"\"\"\n",
    "    Perform a single step of the gradient descent method.\n",
    "    :return: a list containing [clock_before, clock_after] w.r.t. the computation\n",
    "    \"\"\"\n",
    "    # useful vars for estimate the time taken by the computation\n",
    "    t0 = self.local_clock\n",
    "\n",
    "    # avg internal self.W vector with W incoming from dependencies\n",
    "    if self.iteration > 0:\n",
    "        self.avg_weight_with_dependencies()\n",
    "\n",
    "    # compute the gradient descent step\n",
    "    self.training_task.step()\n",
    "\n",
    "    # broadcast the obtained value to all node's recipients\n",
    "    self.broadcast_weight_to_recipients()\n",
    "\n",
    "    # get the counter after the computation has ended\n",
    "    # get the time from an exponential with lambda parameter equal to 1\n",
    "    # whereas lambda = 1 / mean_time, so mean_time = 1\n",
    "    dt = random.expovariate(1)\n",
    "\n",
    "    # computes the clock when the computation has finished\n",
    "    tf = t0 + dt\n",
    "    # update the local_clock\n",
    "    self.local_clock = tf\n",
    "\n",
    "    self.iteration += 1\n",
    "    self.log.append(self.local_clock)\n",
    "\n",
    "    return [t0, tf]\n",
    "```\n",
    "\n",
    "The time taken by a node to perform a single gradient step is handled by a random variable $X \\sim Exp(\\lambda)$ (e.g. exponentially distributed with parameter $\\lambda$) where $\\mathbb{E}[X] = \\frac{1}{\\lambda}$. At the moment $\\lambda$ is fixed to $1$, so, in this case, the mean time is equal to one too.\n",
    "\n",
    "It is not mandatory for you to know all details about how the system actually works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Previous tests - 002 (those made until 25/04/18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New tests - 003 (since 26/04/18)\n",
    "## Main changes from earlier tests\n",
    "1. The number of computational units has been fixed to $n=10$;\n",
    "2. `diam-expander` has lost one edges per node. It is now defined as\n",
    "$$G=(V=\\{0,...n-1\\},E=\\{(i, i+1\\text{ mod }n), (i, i+\\frac{n}{2}\\text{ mod }n) : i \\in [n]\\});$$\n",
    "3. a new dependency graph `root-expander` has been considered\n",
    "$$G=(V=\\{0,...n-1\\},E=\\{(i, i+1\\text{ mod }n), (i, i+\\sqrt{n}\\text{ mod }n) : i \\in [n]\\});$$\n",
    "4. at the moment we will focus on testing the classic GD method. Right after obtaining some results for GD, we will test BGD (batch gradient descent) and SGD (stochastic gradient descent) as well;\n",
    "5. all plots \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant fixed parameters\n",
    "```python\n",
    "n = 10\n",
    "seed = str(time.time()) # timestamp\n",
    "graphs = {\n",
    "    # cycle, clique, root-expander, diam-expander, diagonal adjacency matrices\n",
    "}\n",
    "\n",
    "# TRAINING SET SETUP\n",
    "n_features = 100\n",
    "yhat = <class 'src.mltoolbox.LinearYHatFunction'>\n",
    "domain_radius = 5\n",
    "domain_center = 0\n",
    "error_mean = 0\n",
    "error_std_dev = 1\n",
    "\n",
    "# CLUSTER SETUP\n",
    "sample_function = <function LinearYHatFunction.f at 0x7f13fa4d00d0>\n",
    "max_iter = None\n",
    "max_time = 10000\n",
    "method = 'classic'\n",
    "loss = <class 'src.mltoolbox.SquaredLossFunction'>\n",
    "penalty = l2\n",
    "epsilon = 0.01\n",
    "alpha = 1e-06\n",
    "learning_rate = constant\n",
    "metrics = all\n",
    "alt_metrics = False\n",
    "shuffle = True\n",
    "verbose = False\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter we will focus particularly on and the only which will vary is `n_samples`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 samples GD test\n",
    "`n_samples = 100`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 sample GD test - Iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100samples_classic/1_iter_time.png)\n",
    "This trend will be a constant through all future tests: the less the nodes' connections the fastest the system can advance in iterations.\n",
    "\n",
    "As expected, in diagonal topology, since nodes never wait still and since the mean of the time taken by each iteration is equal to 1, then such topology always achieves an amount of iterations approximately equal to the time of the simulation. This plot makes us notice that the amount of iteration achieved by each topology depends, in some way, on the graph's degree (e.g. number of dependency established among nodes). We would like to study in depth this intuition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 sample GD test - MSE over iterations\n",
    "![MSE over iter](media/img/tests/test_003_100samples_classic/2_mse_iter.png)\n",
    "Due to restricted training set size, a single node doesn't own enough samples to achieve a good model without communicating with other nodes, therefore diagonal topology performs far worse than the others, which in turn behave almost equally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - RMSE over iterations\n",
    "![RMSE over iter](media/img/tests/test_003_100samples_classic/2_real-mse_iter.png)\n",
    "RMSE/iter plot doesn't suggest anything more than MSE/iter already does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100samples_classic/3_mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100 samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100samples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_100samples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "As already seen in previous plots for this test, diagonal topology, unlike all the others, never achieves a good prediction model. \n",
    "\n",
    "The cycle turns out to be the fastest.\n",
    "\n",
    "2-degree graphs plots (root expander and diameter expander) are very close.\n",
    "\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1k samples GD test\n",
    "`n_samples = 1000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_1ksamples_classic/1_iter_time.png)\n",
    "Almost the same result as in 100 samples test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_classic/2_mse_iter.png)\n",
    "![MSE over iterations zoom](media/img/tests/test_003_1ksamples_classic/2_mse_iter_zoom.png)\n",
    "\n",
    "Now, since the amount of samples in the training set is equal to 1000, each node $i$ owns a subsample $\\mathcal{X}_i \\subset \\mathcal{X}$ such that $|\\mathcal{X}_i| = 100$ (when for $|\\mathcal{X}|=100$, $|\\mathcal{X}_i|=10$). Such condition seems enough for the diagonal topology to perform similarly as those with communications enabled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_1ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_1ksamples_classic/2_real-mse_iter_zoom.png)\n",
    "By comparing MSE/iter and RMSE/iter, we notice that diagonal topology suffers noise more than others topologies do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_1ksamples_classic/3_mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_1ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "Despite the behaviour of topologies, with respect to **convergence speed**, is almost the same as the one observed in the _100 samples test MSE/time plot_, now diagonal topology doesn't behave so  anymore. \n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10k samples test\n",
    "`n_samples = 10000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_10ksamples_classic/1_iter_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_10ksamples_classic/2_mse_iter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_10ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_10ksamples_classic/2_real-mse_iter_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_10ksamples_classic/3_mse_time.png)\n",
    "![MSE over time_zoom](media/img/tests/test_003_10ksamples_classic/3_mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_10ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_10ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "With $10000$ samples diagonal outperforms others topologies with regard to either MSE/time and RMSE/time plots.\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100k samples GD test\n",
    "`n_samples = 100000`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100ksamples_classic/1_iter_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_100ksamples_classic/2_mse_iter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_100ksamples_classic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_100ksamples_classic/2_real-mse_iter_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100ksamples_classic/3_mse_time.png)\n",
    "![MSE over time_zoom](media/img/tests/test_003_100ksamples_classic/3_mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100k samples GD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100ksamples_classic/3_real-mse_time.png)\n",
    "![RMSE over time_zoom](media/img/tests/test_003_100ksamples_classic/3_real-mse_time_zoom.png)\n",
    "\n",
    "_The same test with different seeds has led to almost identical results._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the training set gets bigger, diagonal topology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Below test with 100 and 1000 samples repeated with `method='stochastic'` instead of classic for the gradient descent.\n",
    "\n",
    "## 100 samples SGD test\n",
    "\n",
    "### 100 samples SGD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_100samples_stochastic/1_iter_time.png)\n",
    "\n",
    "### 100 samples SGD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_100samples_stochastic/2_mse_iter.png)\n",
    "![MSE over iterations](media/img/tests/test_003_100samples_stochastic/2_mse_iter_zoom.png)\n",
    "\n",
    "### 100 samples SGD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_100samples_stochastic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_100samples_stochastic/2_real-mse_iter_zoom.png)\n",
    "\n",
    "### 100 samples SGD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_100samples_stochastic/3_mse_time.png)\n",
    "\n",
    "### 100 samples SGD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_100samples_stochastic/3_real-mse_time.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1k samples SGD test\n",
    "\n",
    "### 1k samples SGD test - iterations over time\n",
    "![Iterations over time](media/img/tests/test_003_1ksamples_stochastic/1_iter_time.png)\n",
    "\n",
    "### 1k samples SGD test - MSE over iterations\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_mse_iter.png)\n",
    "![MSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_mse_iter_zoom.png)\n",
    "\n",
    "### 1k samples SGD test - RMSE over iterations\n",
    "![RMSE over iterations](media/img/tests/test_003_1ksamples_stochastic/2_real-mse_iter.png)\n",
    "![RMSE over iterations zoom](media/img/tests/test_003_1ksamples_stochastic/2_real-mse_iter_zoom.png)\n",
    "\n",
    "### 1k samples SGD test - MSE over time\n",
    "![MSE over time](media/img/tests/test_003_1ksamples_stochastic/3_mse_time.png)\n",
    "\n",
    "### 1k samples SGD test - RMSE over time\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_stochastic/3_real-mse_time.png)\n",
    "![RMSE over time](media/img/tests/test_003_1ksamples_stochastic/3_real-mse_time_zoom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Something theoretical\n",
    "We've noticed that the iteration' speed is strongly related to the number of connections established among nodes, this is clearly observable in all _iteration over time_ plots. A similar speed gain can be seen in _MSE over time_ plot: whether the amount of samples in the training set is big enough such that even a single node alone can achieve a good solution, then connections are just causes of slowdown. It seems that the gain in speed always matters far more than the gain in information flow due to an high dependency graph's degree. This is only a suggestion given by these early tests.\n",
    "\n",
    "![MSE_over_time](media/img/tests/test_003_10ksamples_classic/3_mse_time_big.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
